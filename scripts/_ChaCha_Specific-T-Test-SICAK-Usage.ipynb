{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "import os\n",
    "import time \n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "import subprocess\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858121ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import SICAK_SPECIFIC_T_TEST as sicak\n",
    "\n",
    "# Reload the module to apply changes\n",
    "importlib.reload(sicak)\n",
    "\n",
    "# Import the updated functions\n",
    "import SICAK_SPECIFIC_T_TEST as sicak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import _ChaCha20_source\n",
    "\n",
    "# Reload the module to apply changes\n",
    "importlib.reload(_ChaCha20_source)\n",
    "\n",
    "# Import the updated functions\n",
    "from _ChaCha20_source import Chacha20, Chacha20Keystream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292646c7",
   "metadata": {},
   "source": [
    "# Helper functions to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = None\n",
    "CHUNKS_CNT = None\n",
    "LAST_CHUNK_SIZE = None\n",
    "\n",
    "TRACE_CNT = None\n",
    "TRACE_LEN = None\n",
    "TRACE_RANDOM_CNT = None\n",
    "\n",
    "NONCES = None\n",
    "NONCE_LEN_BYTES = 12  # Length of each nonce in bytes\n",
    "NONCE_LEN_32BIT = NONCE_LEN_BYTES // 4  # Number of 32-bit integers per nonce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb2ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_info(folder):\n",
    "    \"\"\"Reads the info.txt file to get the number of traces, chunk size, and trace length.\"\"\"\n",
    "    global CHUNK_SIZE, LAST_CHUNK_SIZE, CHUNKS_CNT\n",
    "    with open(f\"{folder}/info.txt\", 'r') as file:\n",
    "        global TRACE_CNT\n",
    "        global TRACE_LEN\n",
    "        global TRACE_RANDOM_CNT\n",
    "        TRACE_CNT = int(file.readline())\n",
    "        TRACE_RANDOM_CNT = TRACE_CNT\n",
    "        CHUNK_SIZE = int(file.readline())\n",
    "        TRACE_LEN = int(file.readline())\n",
    "        \n",
    "    CHUNKS_CNT = math.ceil(TRACE_CNT / CHUNK_SIZE)\n",
    "    LAST_CHUNK_SIZE = TRACE_CNT - (CHUNKS_CNT - 1)* CHUNK_SIZE\n",
    "    print(f\"TRACE_CNT = {TRACE_CNT}\")   \n",
    "    print(f\"CHUNK_SIZE = {CHUNK_SIZE}\")   \n",
    "    print(f\"LAST_CHUNK_SIZE = {LAST_CHUNK_SIZE}\")   \n",
    "    print(f\"CHUNKS_CNT = {CHUNKS_CNT}\")   \n",
    "    print(f\"TRACE_RANDOM_CNT = {TRACE_RANDOM_CNT}\")   \n",
    "    print(f\"TRACE_LEN = {TRACE_LEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fae306",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_nonces(folder):\n",
    "    \"\"\"Reads the nonces from the binary files in the specified folder.\"\"\"\n",
    "    global NONCES, CHUNK_SIZE, LAST_CHUNK_SIZE, CHUNKS_CNT, TRACE_CNT\n",
    "    \n",
    "    nonces_list = []\n",
    "    for chunk_index in range(CHUNKS_CNT):\n",
    "        print(f\"Processing CHUNK - {chunk_index}\")\n",
    "        chunk_folder = os.path.join(folder, f\"chunk_{chunk_index}\")\n",
    "        chunk_file = os.path.join(chunk_folder, \"nonces_random.bin\")\n",
    "        \n",
    "        if os.path.exists(chunk_file):\n",
    "            with open(chunk_file, 'rb') as file:\n",
    "                byte_array = file.read()\n",
    "            \n",
    "            if chunk_index != CHUNKS_CNT - 1:\n",
    "                chunk = np.frombuffer(byte_array, dtype=np.uint32).reshape((CHUNK_SIZE, NONCE_LEN_32BIT))\n",
    "            else:\n",
    "                chunk = np.frombuffer(byte_array, dtype=np.uint32).reshape((LAST_CHUNK_SIZE, NONCE_LEN_32BIT))\n",
    "            nonces_list.append(chunk)\n",
    "        else:\n",
    "            print(f\"Chunk file {chunk_file} does not exist.\")\n",
    "    \n",
    "    # Concatenate all chunks\n",
    "    NONCES = np.vstack(nonces_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeca4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_traces_into_one_file(folder):\n",
    "    \"\"\"Compresses all traces from multiple chunk files into a single binary file within the folder provided.\"\"\"\n",
    "    output_file = os.path.join(folder, \"traces_random_all.bin\")\n",
    "\n",
    "    # Open the output file in write-binary mode\n",
    "    with open(output_file, 'wb') as outfile:\n",
    "        for chunk_index in range(CHUNKS_CNT):\n",
    "            chunk_folder = os.path.join(folder, f\"chunk_{chunk_index}\")\n",
    "            chunk_file = os.path.join(chunk_folder, \"traces_random.bin\")\n",
    "\n",
    "            print(f\"Processing CHUNK - {chunk_index}\")\n",
    "\n",
    "            # Check if the chunk file exists\n",
    "            if os.path.exists(chunk_file):\n",
    "                # Open the chunk file in read-binary mode\n",
    "                with open(chunk_file, 'rb') as infile:\n",
    "                    # Read the contents of the chunk file\n",
    "                    chunk_data = infile.read()\n",
    "                    # Write the contents to the output file\n",
    "                    outfile.write(chunk_data)\n",
    "            else:\n",
    "                print(f\"Chunk file {chunk_file} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c318429",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_const = b\"expand 32-byte k\"\n",
    "# Convert the byte string to an array of 32-bit unsigned integers\n",
    "sigma_const = np.frombuffer(sigma_const, dtype=np.uint32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ea8085",
   "metadata": {},
   "source": [
    "# Helper functions to split traces, calculate intermediate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_ARRAY = None\n",
    "LF0 = 0\n",
    "LF1 = 1\n",
    "def leftRotate16(n):\n",
    "    return ((n << 16) | (n >> 16)) & 0xFFFFFFFF\n",
    "\n",
    "def calculate_intermediate_value(function_index, byte_index, key, nonce=None, sigma=None, previous_intermediate_value=None, recovered_key=None):\n",
    "    \"\"\"\n",
    "    Calculate the intermediate value based on the function index and byte index.\n",
    "    The function index determines which calculation to perform, and the byte index specifies which byte of the result to return.\n",
    "\n",
    "    Parameters:\n",
    "    - function_index (int): The index of the function to use (0 or 1).\n",
    "    - byte_index (int): The index of the byte to return (0 to 3).\n",
    "    - key (int): The key value (32-bit unsigned integer).\n",
    "    - nonce (int, optional): The nonce value (32-bit unsigned integer) for function index 0.\n",
    "    - sigma (int, optional): The sigma value (32-bit unsigned integer) for function index 0.\n",
    "    - previous_intermediate_value (int, optional): The previous intermediate value (32-bit unsigned integer) for function index 1.\n",
    "    - recovered_key (int, optional): The recovered key value (32-bit unsigned integer) for function index 1.\n",
    "\n",
    "    Returns:\n",
    "    - int: The calculated intermediate value (8-bit unsigned integer).\n",
    "    \"\"\"\n",
    "    shift = byte_index * 8\n",
    "    if byte_index < 0 or byte_index > 3:\n",
    "        raise Exception(\"Invalid byte index\")\n",
    "    \n",
    "    if function_index == 0:\n",
    "        # Usage of basic leakage function: nonce ^ (key + sigma)\n",
    "        if sigma is None or nonce is None:\n",
    "            raise Exception(\"Sigma value is required for this calculation\")\n",
    "        return ((nonce ^ (key + sigma)) >> shift) & 0xFF\n",
    "    elif function_index == 1:\n",
    "        # Usage of advanced leakage function: (key + leftRotate16(previous_intermediate_value)) ^ recovered_key\n",
    "        # The leftRotate16 function is used to rotate the previous intermediate value by 16 bits\n",
    "        # The previous intermediate value is calculated using the basic leakage function\n",
    "        if previous_intermediate_value is None or recovered_key is None:\n",
    "            raise Exception(\"Previous intermediate value and recovered key are required for this calculation\")\n",
    "        rotated_value = leftRotate16(previous_intermediate_value)\n",
    "        return ((key + rotated_value) ^ recovered_key) >> shift & 0xFF\n",
    "    else:\n",
    "        raise Exception(\"Invalid LF index\")\n",
    "        \n",
    "def calculate_state_s1():\n",
    "    \"\"\"\n",
    "    Calculate the S[1] state matrix for the given traces and nonces.\n",
    "    The S[1] state matrix is a 4x4 matrix of 32-bit values, where each value is derived from the keystream generated by the ChaCha20 algorithm.\n",
    "    \"\"\"\n",
    "    # Calculate the S[1] - TRACE_CNT * State matrix (4x4 32bit values)\n",
    "    s1_array = np.zeros((TRACE_CNT, 4 * 4), dtype=np.uint32)\n",
    "    # Iterate over each trace\n",
    "    for i in range(TRACE_CNT):\n",
    "        # Get the nonce for the current trace\n",
    "        nonce = NONCES[i]\n",
    "        # Generate the keystream using the correct key and nonce\n",
    "        keystream = Chacha20Keystream(CORRECT_KEY, nonce, rounds=1)\n",
    "\n",
    "        # Reshape the keystream into a 4x4 matrix and store it in the S[1] matrix\n",
    "        s1_array[i] = np.array(keystream)\n",
    "    return s1_array\n",
    "\n",
    "# ORIGINAL VERSION, WHICH DOES NOT SUPPORT LA FOR STATE S1[0] and S1[12], ONLY SUPPORTS S1[4] and S1[8]\n",
    "def calculate_intermediate_values(byte_index):\n",
    "    \"\"\"\n",
    "    Calculate the intermediate values for a specific byte index.\n",
    "    The byte index determines which byte of the result to return.\n",
    "\n",
    "    Parameters:\n",
    "    - byte_index (int): The index of the byte to return (0 to 31).\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: The calculated intermediate values (8-bit unsigned integers).\n",
    "    \"\"\"\n",
    "    global TRACE_CNT, LF0, LF1, NONCES, sigma_const, S1_ARRAY, CORRECT_KEY\n",
    "    intermediate_values = np.zeros(TRACE_CNT, dtype=np.uint8)\n",
    "    if byte_index in range(0,4):\n",
    "        # Handle byte_index values from 0 to 3\n",
    "        if S1_ARRAY is None:\n",
    "            raise Exception(\"S1 array is required for this calculation\")\n",
    "        # Calculate the intermediate values\n",
    "        for i in range(TRACE_CNT):\n",
    "            state_s1_key = S1_ARRAY[i][4]\n",
    "            state_s1_sigma = S1_ARRAY[i][3]\n",
    "            state_s1_nonce = S1_ARRAY[i][14]\n",
    "            intermediate_values[i] = calculate_intermediate_value(LF0, byte_index % 4, state_s1_key, nonce=state_s1_nonce, sigma=state_s1_sigma)\n",
    "    elif byte_index in range(4,16):\n",
    "        # Handle byte_index values from 4 to 15\n",
    "        col_index = byte_index // 4\n",
    "        key = CORRECT_KEY[col_index]\n",
    "        sigma = sigma_const[col_index]\n",
    "        for i in range(TRACE_CNT):\n",
    "            nonce = NONCES[i][col_index - 1]\n",
    "            intermediate_values[i] = calculate_intermediate_value(LF0, byte_index % 4, key, nonce=nonce, sigma=sigma)\n",
    "    elif byte_index in range(16,20):\n",
    "        # Handle byte_index values from 16 to 19\n",
    "        if S1_ARRAY is None:\n",
    "            raise Exception(\"S1_ARRAY is required for this calculation\")\n",
    "        # Calculate the intermediate values\n",
    "        for i in range(TRACE_CNT):\n",
    "            state_s1_sigma    = S1_ARRAY[i][2]\n",
    "            state_s1_prev_key = S1_ARRAY[i][7]\n",
    "            state_s1_key      = S1_ARRAY[i][8]\n",
    "            state_s1_nonce    = S1_ARRAY[i][13]\n",
    "            prev_i_v = state_s1_nonce ^ ((state_s1_prev_key + state_s1_sigma) & 0xFFFFFFFF)\n",
    "            intermediate_values[i] = calculate_intermediate_value(LF1, byte_index % 4, state_s1_key, nonce=None, sigma=None, previous_intermediate_value=prev_i_v, recovered_key=state_s1_prev_key)\n",
    "    elif byte_index in range(20,32):\n",
    "        col_index = (byte_index - 16) // 4\n",
    "        prev_key = CORRECT_KEY[col_index]\n",
    "        sigma = sigma_const[col_index]\n",
    "        key = CORRECT_KEY[col_index + 4]\n",
    "\n",
    "        for i in range(TRACE_CNT):\n",
    "            prev_i_v = NONCES[i][col_index - 1] ^ ((prev_key + sigma) & 0xFFFFFFFF)\n",
    "            intermediate_values[i] = calculate_intermediate_value(LF1, byte_index % 4, key, nonce=None, sigma=None, previous_intermediate_value=prev_i_v, recovered_key=prev_key)\n",
    "    else:\n",
    "        raise Exception(\"Not implemented\")\n",
    "    \n",
    "    return intermediate_values\n",
    "\n",
    "# ADDITIONAL VERSION, WHICH DOES NOT SUPPORT LA FOR KEY BYTES, BUT SUPPORTS LA FOR STATE S1[0], S1[12], S1[4], and S1[8]\n",
    "def calculate_intermediate_values_S1_column(word_index, byte_index):\n",
    "    \"\"\"\n",
    "    Calculate the intermediate values for a specific column of the S[1] state matrix.\n",
    "    The column is specified by the word index and byte index.\n",
    "    The word index determines which column to use (0, 4, 8, or 12), and the byte index specifies which byte of the result to return.\n",
    "\n",
    "    Parameters:\n",
    "    - word_index (int): The index of the word to use (0, 4, 8, or 12).\n",
    "    - byte_index (int): The index of the byte to return (0 to 3).\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: The calculated intermediate values (8-bit unsigned integers).\n",
    "    \"\"\"\n",
    "\n",
    "    global S1_ARRAY, TRACE_CNT, LF0, LF1\n",
    "\n",
    "    if S1_ARRAY is None:\n",
    "            raise Exception(\"S1 array is required for this calculation\")\n",
    "\n",
    "    if word_index not in [0, 4, 8, 12]:\n",
    "        raise Exception(\"Invalid word index. Must be one of [0, 4, 8, 12]\")\n",
    "    \n",
    "    if byte_index not in range(0, 4):\n",
    "        raise Exception(\"Invalid byte index. Must be in range [0, 4)\")\n",
    "    \n",
    "    intermediate_values = np.zeros(TRACE_CNT, dtype=np.uint8)        \n",
    "    if word_index == 0:\n",
    "        for i in range(TRACE_CNT):\n",
    "            Sx = S1_ARRAY[i][0]\n",
    "            Sy = S1_ARRAY[i][5]\n",
    "            Sz = S1_ARRAY[i][15]\n",
    "            intermediate_values[i] = calculate_intermediate_value(LF0, byte_index, key=Sy, nonce=Sz, sigma=Sx)\n",
    "    elif word_index == 4:\n",
    "        for i in range(TRACE_CNT):\n",
    "            Sx = S1_ARRAY[i][3]\n",
    "            Sy = S1_ARRAY[i][4]\n",
    "            Sz = S1_ARRAY[i][14]\n",
    "            intermediate_values[i] = calculate_intermediate_value(LF0, byte_index, key=Sy, nonce=Sz, sigma=Sx)\n",
    "\n",
    "    elif word_index == 8:\n",
    "        for i in range(TRACE_CNT):\n",
    "            Sx = S1_ARRAY[i][2]\n",
    "            Sy = S1_ARRAY[i][7]\n",
    "            Sz = S1_ARRAY[i][13]\n",
    "            Sk = S1_ARRAY[i][8]\n",
    "            prev_i_v = Sz ^ ((Sy + Sx) & 0xFFFFFFFF)\n",
    "            intermediate_values[i] = calculate_intermediate_value(LF1, byte_index, key=Sk, nonce=None, sigma=None, previous_intermediate_value=prev_i_v, recovered_key=Sy)\n",
    "    elif word_index == 12:\n",
    "        for i in range(TRACE_CNT):\n",
    "            Sx = S1_ARRAY[i][1]\n",
    "            Sy = S1_ARRAY[i][6]\n",
    "            Sz = S1_ARRAY[i][12]\n",
    "            intermediate_values[i] = calculate_intermediate_value(LF0, byte_index, key=Sy, nonce=Sz, sigma=Sx)\n",
    "    else:\n",
    "        raise Exception(\"Not implemented\")\n",
    "    \n",
    "    return intermediate_values\n",
    "\n",
    "# Define a named tuple to hold the t-test results\n",
    "from collections import namedtuple\n",
    "TTestResult = namedtuple('TTestResult', ['statistic', 'pvalue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d7c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL VERSION, WHICH DOES NOT SUPPORT LA FOR STATE S1[0] and S1[12], ONLY SUPPORTS S1[4] and S1[8]\n",
    "def sort_traces_and_split(output_folder, input_file = \"traces_random_all.bin\", chunks = 10, byte_index=0, byte_value=0x00):\n",
    "    \"\"\"\n",
    "    Sort traces based on the intermediate value at a specific byte index.\n",
    "\n",
    "    This function sorts traces into chunks paired files, where each chunk contains traces that either match or do not match the specified byte value at the given byte index.\n",
    "    The traces are read from the input file, and the sorted traces are saved into separate files in the specified output folder.\n",
    "\n",
    "    Args:\n",
    "        output_folder (str): The folder where the sorted traces will be saved.\n",
    "        input_file (str): The input file containing the traces (default is \"traces_random_all.bin\").\n",
    "        chunks (int): The number of chunks, into which is the input_file divided (default is 10).\n",
    "        byte_index (int): The byte index to check in the intermediate value.\n",
    "        byte_value (int): The byte value to compare against (default is 0x00).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    global TRACE_LEN, TRACE_CNT\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\".byte index = {byte_index}, byte value = {hex(byte_value)}\")\n",
    "\n",
    "    # Precalculate intermediate values\n",
    "    intermediate_values = calculate_intermediate_values(byte_index)\n",
    "    print(f\"..intermediate values calculated - size {len(intermediate_values)}\")\n",
    "\n",
    "    # Initialize output folder\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Initialize output files for 10 chunks\n",
    "    equal_files = [\n",
    "        open(os.path.join(output_folder, f\"traces_equal_{byte_index:02x}_{byte_value:02x}-{chunk}.bin\"), 'wb')\n",
    "        for chunk in range(chunks)\n",
    "    ]\n",
    "    not_equal_files = [\n",
    "        open(os.path.join(output_folder, f\"traces_not_equal_{byte_index:02x}_{byte_value:02x}-{chunk}.bin\"), 'wb')\n",
    "        for chunk in range(chunks)\n",
    "    ]\n",
    "\n",
    "    # Open the input file\n",
    "    with open(input_file, 'rb') as infile:\n",
    "        # Iterate over the traces and sort them directly into chunks\n",
    "        for i in range(TRACE_CNT):\n",
    "            trace = np.frombuffer(infile.read(TRACE_LEN * np.dtype(np.uint16).itemsize), dtype=np.uint16)\n",
    "            chunk_index = (i * chunks) // TRACE_CNT  # Determine the chunk index (0-9)\n",
    "\n",
    "            if intermediate_values[i] == byte_value:\n",
    "                equal_files[chunk_index].write(trace.tobytes())\n",
    "            else:\n",
    "                not_equal_files[chunk_index].write(trace.tobytes())\n",
    "\n",
    "    # Close all output files\n",
    "    for f in equal_files + not_equal_files:\n",
    "        f.close()\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    duration_seconds = end_time - start_time\n",
    "    print(f\"Traces sorted and split into {chunks} parts. Duration: {duration_seconds:.2f} seconds\")\n",
    "\n",
    "# ADDITIONAL VERSION, WHICH DOES NOT SUPPORT LA FOR KEY BYTES, BUT SUPPORTS LA FOR STATE S1[0], S1[12], S1[4], and S1[8]\n",
    "def sort_traces_and_split_s1(output_folder, input_file = \"traces_random_all.bin\", chunks = 10, word_index=0, byte_index=0, byte_value=0x00):\n",
    "    \"\"\"\n",
    "    Sort traces based on the intermediate value at a specific word index and byte index.\n",
    "\n",
    "    NOTE: This function is specifically designed ad-hoc for the first column of S[1] state matrix, which is a 4x4 matrix of 32-bit values.\n",
    "\n",
    "    This function sorts traces into chunks paired files, where each chunk contains traces that either match or do not match the specified byte value at the given byte index.\n",
    "    The traces are read from the input file, and the sorted traces are saved into separate files in the specified output folder.\n",
    "\n",
    "    Args:\n",
    "        output_folder (str): The folder where the sorted traces will be saved.\n",
    "        input_file (str): The input file containing the traces (default is \"traces_random_all.bin\").\n",
    "        chunks (int): The number of chunks, into which is the input_file divided (default is 10).\n",
    "        word_index (int): The word index to check in the intermediate value (0, 4, 8, or 12).\n",
    "        byte_index (int): The byte index to check in the intermediate value. (0 to 3).\n",
    "        byte_value (int): The byte value to compare against (default is 0x00).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    global TRACE_LEN, TRACE_CNT\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\".word_index = {word_index}, byte index = {byte_index}, byte value = {hex(byte_value)}\")\n",
    "\n",
    "    # Precalculate intermediate values\n",
    "    intermediate_values = calculate_intermediate_values_S1_column(word_index, byte_index)\n",
    "    print(f\"..intermediate values calculated - size {len(intermediate_values)}\")\n",
    "\n",
    "    # Initialize output folder\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Initialize output files for 10 chunks\n",
    "    equal_files = [\n",
    "        open(os.path.join(output_folder, f\"traces_equal_{word_index:02x}_{byte_index:02x}_{byte_value:02x}-{chunk}.bin\"), 'wb')\n",
    "        for chunk in range(chunks)\n",
    "    ]\n",
    "    not_equal_files = [\n",
    "        open(os.path.join(output_folder, f\"traces_not_equal_{word_index:02x}_{byte_index:02x}_{byte_value:02x}-{chunk}.bin\"), 'wb')\n",
    "        for chunk in range(chunks)\n",
    "    ]\n",
    "\n",
    "    # Open the input file\n",
    "    with open(input_file, 'rb') as infile:\n",
    "        # Iterate over the traces and sort them directly into chunks\n",
    "        for i in range(TRACE_CNT):\n",
    "            trace = np.frombuffer(infile.read(TRACE_LEN * np.dtype(np.uint16).itemsize), dtype=np.uint16)\n",
    "            chunk_index = (i * chunks) // TRACE_CNT  # Determine the chunk index (0-9)\n",
    "\n",
    "            if intermediate_values[i] == byte_value:\n",
    "                equal_files[chunk_index].write(trace.tobytes())\n",
    "            else:\n",
    "                not_equal_files[chunk_index].write(trace.tobytes())\n",
    "\n",
    "    # Close all output files\n",
    "    for f in equal_files + not_equal_files:\n",
    "        f.close()\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    duration_seconds = end_time - start_time\n",
    "    print(f\"Traces sorted and split into {chunks} parts. Duration: {duration_seconds:.2f} seconds\")\n",
    "    \n",
    "def clean_up_trace_files(folder, equal_prefix, not_equal_prefix):\n",
    "    \"\"\"\n",
    "    Remove files with specified prefixes (e.g., traces_equal and traces_not_equal) from the given folder.\n",
    "\n",
    "    Parameters:\n",
    "        folder (str): Path to the folder containing the trace files.\n",
    "        equal_prefix (str): Prefix for equal trace files (e.g., \"traces_equal\").\n",
    "        not_equal_prefix (str): Prefix for not-equal trace files (e.g., \"traces_not_equal\").\n",
    "    \"\"\"\n",
    "    # Iterate over the files in the folder\n",
    "    for filename in os.listdir(folder):\n",
    "        # Check if the file starts with the specified prefixes\n",
    "        if filename.startswith(equal_prefix) or filename.startswith(not_equal_prefix):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Removed file: {file_path}\")\n",
    "            except OSError as e:\n",
    "                print(f\"Error removing file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0e51a1",
   "metadata": {},
   "source": [
    "# T-test calculation using SICAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0020c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_prefix = \"traces_equal\"\n",
    "not_equal_prefix = \"traces_not_equal\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec60b52",
   "metadata": {},
   "source": [
    "## Specific t-test for STM - Key 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea48c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_folder = \"ChaCha-1000-000-Random-Nonce-STM\"\n",
    "output_folder = \"_LA-STM-1-TEST\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa07753",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECT_KEY = np.fromfile(f\"{traces_folder}/key.bin\", dtype=np.uint32)\n",
    "\n",
    "read_info(traces_folder)\n",
    "read_nonces(traces_folder)\n",
    "compress_traces_into_one_file(traces_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_ARRAY = calculate_state_s1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baadccbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for byte_pos in chain(range(32)): #byte pos 0 - 31\n",
    "    for byte_value in range(0x100): #0x00 - 0xff\n",
    "        # Print the current time\n",
    "        print(f\"Byte[{byte_pos}], Value = {hex(byte_value)}, Current time: \", datetime.now())\n",
    "        \n",
    "        sort_traces_and_split(output_folder, input_file = f\"{traces_folder}\\\\traces_random_all.bin\",\n",
    "                      chunks = 10, byte_index=byte_pos, byte_value=byte_value)\n",
    "        \n",
    "        \n",
    "        sicak.perform_t_test(folder=output_folder, \n",
    "                             trace_len=TRACE_LEN, \n",
    "                             file_count=10,\n",
    "                             output_file_name=f\"t_stats_{byte_pos}_{byte_value:02x}.npy\", \n",
    "                             file_equal_prefix=f\"traces_equal_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                             file_not_equal_prefix=f\"traces_not_equal_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                             stan_exe_path = r\".\\..\\sicak-1.2.1\\stan.exe\")\n",
    "        \n",
    "        clean_up_trace_files(output_folder, equal_prefix, not_equal_prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7e9d49",
   "metadata": {},
   "source": [
    "## Specific t-test for STM - Key 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3107d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_folder = \"ChaCha-1000-000-Random-Nonce-STM-2\"\n",
    "output_folder = \"_LA-STM-2\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611221e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECT_KEY = np.fromfile(f\"{traces_folder}/key.bin\", dtype=np.uint32)\n",
    "\n",
    "read_info(traces_folder)\n",
    "read_nonces(traces_folder)\n",
    "compress_traces_into_one_file(traces_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b55d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_ARRAY = calculate_state_s1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064af156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for byte_pos in chain(range(0, 32)): #byte pos 0 - 31\n",
    "    for byte_value in range(0x100): #0x00 - 0xff\n",
    "        # Print the current time\n",
    "        print(f\"Byte[{byte_pos}], Value = {hex(byte_value)}, Current time: \", datetime.now())\n",
    "        \n",
    "        sort_traces_and_split(output_folder, input_file = f\"{traces_folder}\\\\traces_random_all.bin\",\n",
    "                      chunks = 10, byte_index=byte_pos, byte_value=byte_value)\n",
    "        \n",
    "        \n",
    "        sicak.perform_t_test(folder=output_folder, \n",
    "                             trace_len=TRACE_LEN, \n",
    "                             file_count=10,\n",
    "                             output_file_name=f\"t_stats_{byte_pos}_{byte_value:02x}.npy\", \n",
    "                             file_equal_prefix=f\"traces_equal_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                             file_not_equal_prefix=f\"traces_not_equal_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                             stan_exe_path = r\".\\..\\sicak-1.2.1\\stan.exe\")\n",
    "        \n",
    "        clean_up_trace_files(output_folder, equal_prefix, not_equal_prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62122369",
   "metadata": {},
   "source": [
    "## Specific t-test for XMEGA - Key 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e65031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_folder = \"ChaCha-1000-000-Random-Nonce-XMEGA\"\n",
    "output_folder = \"_LA-XMEGA-1\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075045a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECT_KEY = np.fromfile(f\"{traces_folder}/key.bin\", dtype=np.uint32)\n",
    "\n",
    "read_info(traces_folder)\n",
    "read_nonces(traces_folder)\n",
    "compress_traces_into_one_file(traces_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c3d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_ARRAY = calculate_state_s1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced57346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for byte_pos in chain(range(0, 32)): #byte pos 0 - 31\n",
    "    for byte_value in range(0x100): #0x00 - 0xff\n",
    "        # Print the current time\n",
    "        print(f\"Byte[{byte_pos}], Value = {hex(byte_value)}, Current time: \", datetime.now())\n",
    "        \n",
    "        sort_traces_and_split(output_folder, input_file = f\"{traces_folder}\\\\traces_random_all.bin\",\n",
    "                      chunks = 10, byte_index=byte_pos, byte_value=byte_value)\n",
    "        \n",
    "        \n",
    "        sicak.perform_t_test(folder=output_folder, \n",
    "                             trace_len=TRACE_LEN, \n",
    "                             file_count=10,\n",
    "                             output_file_name=f\"t_stats_{byte_pos}_{byte_value:02x}.npy\", \n",
    "                             file_equal_prefix=f\"traces_equal_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                             file_not_equal_prefix=f\"traces_not_equal_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                             stan_exe_path = r\".\\..\\sicak-1.2.1\\stan.exe\")\n",
    "        \n",
    "        clean_up_trace_files(output_folder, equal_prefix, not_equal_prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a398d7",
   "metadata": {},
   "source": [
    "## Specific t-test for XMEGA - Key 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee0fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_folder = \"ChaCha-1000-000-Random-Nonce-XMEGA-2\"\n",
    "output_folder = \"_LA-XMEGA-2\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e3ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECT_KEY = np.fromfile(f\"{traces_folder}/key.bin\", dtype=np.uint32)\n",
    "\n",
    "read_info(traces_folder)\n",
    "read_nonces(traces_folder)\n",
    "compress_traces_into_one_file(traces_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c868c182",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_ARRAY = calculate_state_s1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a851df6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for byte_pos in chain(range(0, 32)): #byte pos 0 - 31\n",
    "    for byte_value in range(0x100): #0x00 - 0xff\n",
    "        # Print the current time\n",
    "        print(f\"Byte[{byte_pos}], Value = {hex(byte_value)}, Current time: \", datetime.now())\n",
    "        \n",
    "        sort_traces_and_split(output_folder, input_file = f\"{traces_folder}\\\\traces_random_all.bin\",\n",
    "                      chunks = 10, byte_index=byte_pos, byte_value=byte_value)\n",
    "        \n",
    "        \n",
    "        sicak.perform_t_test(folder=output_folder, \n",
    "                             trace_len=TRACE_LEN, \n",
    "                             file_count=10,\n",
    "                             output_file_name=f\"t_stats_{byte_pos}_{byte_value:02x}.npy\", \n",
    "                             file_equal_prefix=f\"traces_equal_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                             file_not_equal_prefix=f\"traces_not_equal_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                             stan_exe_path = r\".\\..\\sicak-1.2.1\\stan.exe\")\n",
    "        \n",
    "        clean_up_trace_files(output_folder, equal_prefix, not_equal_prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb7834",
   "metadata": {},
   "source": [
    "# Additional LA for S1[0] and S1[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_prefix = \"traces_equal\"\n",
    "not_equal_prefix = \"traces_not_equal\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f8616",
   "metadata": {},
   "source": [
    "## Specific t-test for STM - Key 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_folder = \"ChaCha-1000-000-Random-Nonce-STM\"\n",
    "output_folder = \"_LA-STM-1-ADDITIONAL-S1-WORDS\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e98d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54366955",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECT_KEY = np.fromfile(f\"{traces_folder}/key.bin\", dtype=np.uint32)\n",
    "\n",
    "read_info(traces_folder)\n",
    "read_nonces(traces_folder)\n",
    "compress_traces_into_one_file(traces_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_ARRAY = calculate_state_s1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc7b7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_pos in [0,12]:\n",
    "    for byte_pos in chain(range(4)):\n",
    "        for byte_value in range(0x100):\n",
    "            # Print the current time\n",
    "            print(f\"State [{word_pos}] Byte[{byte_pos}], Value = {hex(byte_value)}, Current time: \", datetime.now())\n",
    "            \n",
    "            sort_traces_and_split_s1(output_folder, input_file = f\"{traces_folder}\\\\traces_random_all.bin\",\n",
    "                        chunks = 10, word_index=word_pos, byte_index=byte_pos, byte_value=byte_value)\n",
    "            \n",
    "            \n",
    "            sicak.perform_t_test(folder=output_folder, \n",
    "                                 trace_len=TRACE_LEN, \n",
    "                                 file_count=10,\n",
    "                                 output_file_name=f\"t_stats_{word_pos}_{byte_pos}_{byte_value:02x}.npy\", \n",
    "                                 file_equal_prefix=f\"traces_equal_{word_pos:02x}_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                                 file_not_equal_prefix=f\"traces_not_equal_{word_pos:02x}_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                                 stan_exe_path = r\".\\..\\sicak-1.2.1\\stan.exe\")\n",
    "            \n",
    "            clean_up_trace_files(output_folder, equal_prefix, not_equal_prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0807f2d",
   "metadata": {},
   "source": [
    "## Specific t-test for STM - Key 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8bfd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_folder = \"ChaCha-1000-000-Random-Nonce-STM-2\"\n",
    "output_folder = \"_LA-STM-2-ADDITIONAL-S1-WORDS\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ab53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cd5094",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECT_KEY = np.fromfile(f\"{traces_folder}/key.bin\", dtype=np.uint32)\n",
    "\n",
    "read_info(traces_folder)\n",
    "read_nonces(traces_folder)\n",
    "compress_traces_into_one_file(traces_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824eca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_ARRAY = calculate_state_s1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03376574",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_pos in [0,12]:\n",
    "    for byte_pos in chain(range(4)):\n",
    "        for byte_value in range(0x100):\n",
    "            # Print the current time\n",
    "            print(f\"State [{word_pos}] Byte[{byte_pos}], Value = {hex(byte_value)}, Current time: \", datetime.now())\n",
    "            \n",
    "            sort_traces_and_split_s1(output_folder, input_file = f\"{traces_folder}\\\\traces_random_all.bin\",\n",
    "                        chunks = 10, word_index=word_pos, byte_index=byte_pos, byte_value=byte_value)\n",
    "            \n",
    "            \n",
    "            sicak.perform_t_test(folder=output_folder, \n",
    "                                 trace_len=TRACE_LEN, \n",
    "                                 file_count=10,\n",
    "                                 output_file_name=f\"t_stats_{word_pos}_{byte_pos}_{byte_value:02x}.npy\", \n",
    "                                 file_equal_prefix=f\"traces_equal_{word_pos:02x}_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                                 file_not_equal_prefix=f\"traces_not_equal_{word_pos:02x}_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                                 stan_exe_path = r\".\\..\\sicak-1.2.1\\stan.exe\")\n",
    "            \n",
    "            clean_up_trace_files(output_folder, equal_prefix, not_equal_prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fead8e",
   "metadata": {},
   "source": [
    "## Specific t-test for STM - Key 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_folder = \"ChaCha-1000-000-Random-Nonce-XMEGA\"\n",
    "output_folder = \"_LA-XMEGA-1-ADDITIONAL-S1-WORDS\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38929601",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a60f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECT_KEY = np.fromfile(f\"{traces_folder}/key.bin\", dtype=np.uint32)\n",
    "\n",
    "read_info(traces_folder)\n",
    "read_nonces(traces_folder)\n",
    "compress_traces_into_one_file(traces_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa1af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_ARRAY = calculate_state_s1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_pos in [0,12]:\n",
    "    for byte_pos in chain(range(4)):\n",
    "        for byte_value in range(0x100):\n",
    "            # Print the current time\n",
    "            print(f\"State [{word_pos}] Byte[{byte_pos}], Value = {hex(byte_value)}, Current time: \", datetime.now())\n",
    "            \n",
    "            sort_traces_and_split_s1(output_folder, input_file = f\"{traces_folder}\\\\traces_random_all.bin\",\n",
    "                        chunks = 10, word_index=word_pos, byte_index=byte_pos, byte_value=byte_value)\n",
    "            \n",
    "            \n",
    "            sicak.perform_t_test(folder=output_folder, \n",
    "                                 trace_len=TRACE_LEN, \n",
    "                                 file_count=10,\n",
    "                                 output_file_name=f\"t_stats_{word_pos}_{byte_pos}_{byte_value:02x}.npy\", \n",
    "                                 file_equal_prefix=f\"traces_equal_{word_pos:02x}_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                                 file_not_equal_prefix=f\"traces_not_equal_{word_pos:02x}_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                                 stan_exe_path = r\".\\..\\sicak-1.2.1\\stan.exe\")\n",
    "            \n",
    "            clean_up_trace_files(output_folder, equal_prefix, not_equal_prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8341a0",
   "metadata": {},
   "source": [
    "## Specific t-test for STM - Key 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_folder = \"ChaCha-100-000-Random-Nonce-XMEGA-2\"\n",
    "output_folder = \"_LA-XMEGA-2-ADDITIONAL-S1-WORDS\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c873a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ebfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECT_KEY = np.fromfile(f\"{traces_folder}/key.bin\", dtype=np.uint32)\n",
    "\n",
    "read_info(traces_folder)\n",
    "read_nonces(traces_folder)\n",
    "compress_traces_into_one_file(traces_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a7a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_ARRAY = calculate_state_s1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_pos in [0,12]:\n",
    "    for byte_pos in chain(range(4)):\n",
    "        for byte_value in range(0x100):\n",
    "            # Print the current time\n",
    "            print(f\"State [{word_pos}] Byte[{byte_pos}], Value = {hex(byte_value)}, Current time: \", datetime.now())\n",
    "            \n",
    "            sort_traces_and_split_s1(output_folder, input_file = f\"{traces_folder}\\\\traces_random_all.bin\",\n",
    "                        chunks = 10, word_index=word_pos, byte_index=byte_pos, byte_value=byte_value)\n",
    "            \n",
    "            \n",
    "            sicak.perform_t_test(folder=output_folder, \n",
    "                                 trace_len=TRACE_LEN, \n",
    "                                 file_count=10,\n",
    "                                 output_file_name=f\"t_stats_{word_pos}_{byte_pos}_{byte_value:02x}.npy\", \n",
    "                                 file_equal_prefix=f\"traces_equal_{word_pos:02x}_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                                 file_not_equal_prefix=f\"traces_not_equal_{word_pos:02x}_{byte_pos:02x}_{byte_value:02x}\",\n",
    "                                 stan_exe_path = r\".\\..\\sicak-1.2.1\\stan.exe\")\n",
    "            \n",
    "            clean_up_trace_files(output_folder, equal_prefix, not_equal_prefix)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
