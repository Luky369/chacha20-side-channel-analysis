{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import os\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOLDER = \"ChaCha-100-000-Fixed-Nonce-XMEGA\"\n",
    "FOLDER = \"ChaCha-100-000-Fixed-Nonce-STM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb2ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIPHERTEXT_LEN_BYTES = 64\n",
    "PLAINTEXT_LEN_BYTES  = CIPHERTEXT_LEN_BYTES\n",
    "TRACE_CNT = None\n",
    "TRACE_LEN = None\n",
    "TRACE_RANDOM_CNT = None\n",
    "CHUNK_SIZE = None\n",
    "CHUNKS_CNT = None\n",
    "LAST_CHUNK_SIZE = None\n",
    "def read_info(folder):\n",
    "    \"\"\"\n",
    "    Read the info.txt file to get the number of traces, chunk size, and trace length.\n",
    "    The info.txt file should contain the following lines:\n",
    "    - Number of traces\n",
    "    - Chunk size\n",
    "    - Trace length\n",
    "    \"\"\"\n",
    "    global CHUNK_SIZE, LAST_CHUNK_SIZE\n",
    "    global CHUNKS_CNT\n",
    "    with open(f\"{folder}/info.txt\", 'r') as file:\n",
    "        global TRACE_CNT\n",
    "        global TRACE_LEN\n",
    "        global TRACE_RANDOM_CNT\n",
    "        TRACE_CNT = int(file.readline())\n",
    "        TRACE_RANDOM_CNT = TRACE_CNT\n",
    "        CHUNK_SIZE = int(file.readline())\n",
    "        TRACE_LEN = int(file.readline())\n",
    "        \n",
    "    CHUNKS_CNT = math.ceil(TRACE_CNT / CHUNK_SIZE)\n",
    "    LAST_CHUNK_SIZE = TRACE_CNT - (CHUNKS_CNT - 1)* CHUNK_SIZE\n",
    "    print(f\"TRACE_CNT = {TRACE_CNT}\")   \n",
    "    print(f\"CHUNK_SIZE = {CHUNK_SIZE}\")   \n",
    "    print(f\"LAST_CHUNK_SIZE = {LAST_CHUNK_SIZE}\")   \n",
    "    print(f\"CHUNKS_CNT = {CHUNKS_CNT}\")   \n",
    "    print(f\"TRACE_RANDOM_CNT = {TRACE_RANDOM_CNT}\")   \n",
    "    print(f\"TRACE_LEN = {TRACE_LEN}\")\n",
    "    \n",
    "    \n",
    "read_info(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd3d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIPHERTEXTS = None\n",
    "def read_ciphertexts(folder):\n",
    "    \"\"\"\n",
    "    Read the ciphertexts from the binary files in the specified folder.\n",
    "    The ciphertexts are stored in chunks, and each chunk is a binary file.\n",
    "    The chunk files are named \"ciphertexts_random.bin\" and are stored in folders named \"chunk_0\", \"chunk_1\", etc.\n",
    "    \"\"\"\n",
    "    global CIPHERTEXTS\n",
    "    global CHUNK_SIZE, LAST_CHUNK_SIZE\n",
    "    global CHUNKS_CNT\n",
    "    global TRACE_CNT\n",
    "    # Calculate the number of chunks\n",
    "    \n",
    "    ciphertexts_list = []\n",
    "    for chunk_index in range(CHUNKS_CNT):\n",
    "        chunk_folder = os.path.join(folder, f\"chunk_{chunk_index}\")\n",
    "        chunk_file = os.path.join(chunk_folder, \"ciphertexts_random.bin\")\n",
    "        \n",
    "        if os.path.exists(chunk_file):\n",
    "            with open(chunk_file, 'rb') as file:\n",
    "                byte_array = file.read()\n",
    "            \n",
    "            if chunk_index != CHUNKS_CNT-1:\n",
    "                chunk_ciphertexts = np.frombuffer(byte_array, dtype=np.uint8).reshape((CHUNK_SIZE, CIPHERTEXT_LEN_BYTES))\n",
    "            else:\n",
    "                chunk_ciphertexts = np.frombuffer(byte_array, dtype=np.uint8).reshape((LAST_CHUNK_SIZE, CIPHERTEXT_LEN_BYTES))\n",
    "\n",
    "            ciphertexts_list.append(chunk_ciphertexts)\n",
    "        else:\n",
    "            print(f\"Chunk file {chunk_file} does not exist.\")\n",
    "    \n",
    "    # Concatenate all chunks\n",
    "    CIPHERTEXTS = np.vstack(ciphertexts_list)\n",
    "        \n",
    "    # Desired shape\n",
    "    desired_shape = (TRACE_CNT, CIPHERTEXT_LEN_BYTES)\n",
    "\n",
    "    # Check if the array has the desired shape\n",
    "    if CIPHERTEXTS.shape != desired_shape:\n",
    "        # Trim the array to the desired shape\n",
    "        print(f\"CIPHERTEXTS.shape != desired_shape - {CIPHERTEXTS.shape} != {desired_shape}\")\n",
    "        CIPHERTEXTS = CIPHERTEXTS[:desired_shape[0], :desired_shape[1]]\n",
    "        print(f\"Trimming CIPHERTEXTS to {CIPHERTEXTS.shape}\")\n",
    "        \n",
    "    ciphertext = CIPHERTEXTS[0]\n",
    "\n",
    "    # Convert each byte to its hexadecimal representation and join them\n",
    "    hex_representation = ''.join(f'{byte:02x}' for byte in ciphertext[:64])\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"CT[0] = {hex_representation}\")\n",
    "    \n",
    "    \n",
    "read_ciphertexts(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb84297",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAINTEXTS = None\n",
    "def read_plaintexts(folder):\n",
    "    \"\"\"\n",
    "    Read the plaintexts from the binary files in the specified folder.\n",
    "    The plaintexts are stored in chunks, and each chunk is a binary file.\n",
    "    The chunk files are named \"plaintexts_random.bin\" and are stored in folders named \"chunk_0\", \"chunk_1\", etc.\n",
    "    \"\"\"\n",
    "    global PLAINTEXTS\n",
    "    global CHUNK_SIZE, LAST_CHUNK_SIZE\n",
    "    global CHUNKS_CNT\n",
    "    global TRACE_CNT\n",
    "    # Calculate the number of chunks\n",
    "    \n",
    "    pts_list = []\n",
    "    for chunk_index in range(CHUNKS_CNT):\n",
    "        chunk_folder = os.path.join(folder, f\"chunk_{chunk_index}\")\n",
    "        chunk_file = os.path.join(chunk_folder, \"plaintexts_random.bin\")\n",
    "        \n",
    "        if os.path.exists(chunk_file):\n",
    "            with open(chunk_file, 'rb') as file:\n",
    "                byte_array = file.read()\n",
    "            \n",
    "            if chunk_index != CHUNKS_CNT-1:\n",
    "                chunk_pts = np.frombuffer(byte_array, dtype=np.uint8).reshape((CHUNK_SIZE, PLAINTEXT_LEN_BYTES))\n",
    "            else:\n",
    "                chunk_pts = np.frombuffer(byte_array, dtype=np.uint8).reshape((LAST_CHUNK_SIZE, PLAINTEXT_LEN_BYTES))\n",
    "\n",
    "            pts_list.append(chunk_pts)\n",
    "        else:\n",
    "            print(f\"Chunk file {chunk_file} does not exist.\")\n",
    "    \n",
    "    # Concatenate all chunks\n",
    "    PLAINTEXTS = np.vstack(pts_list)\n",
    "    \n",
    "    # Desired shape\n",
    "    desired_shape = (TRACE_CNT, PLAINTEXT_LEN_BYTES)\n",
    "\n",
    "    # Check if the array has the desired shape\n",
    "    if PLAINTEXTS.shape != desired_shape:\n",
    "        # Trim the array to the desired shape\n",
    "        PLAINTEXTS = PLAINTEXTS[:desired_shape[0], :desired_shape[1]]\n",
    "        print(f\"Trimming PLAINTEXTS to {PLAINTEXTS.shape}\")\n",
    "        \n",
    "    pt = PLAINTEXTS[0]\n",
    "\n",
    "    # Convert each byte to its hexadecimal representation and join them\n",
    "    hex_representation = ''.join(f'{byte:02x}' for byte in pt[:64])\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"PT[0] = {hex_representation}\")\n",
    "    \n",
    "read_plaintexts(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ca545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the correct key\n",
    "correct_key = np.fromfile(f\"{FOLDER}/key.bin\", dtype=np.uint8)\n",
    "hex_key = ''.join(f'{byte:02x}' for byte in correct_key)\n",
    "print(f\"Correct Key: {hex_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e5277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the nonce used for encryption\n",
    "# The nonce is a 12-byte value, so we read it as uint8\n",
    "# The nonce is stored in a binary file named \"nonce.bin\" in the specified folder.\n",
    "nonce = np.fromfile(f\"{FOLDER}/nonce.bin\", dtype=np.uint8)\n",
    "hex_nonce = ''.join(f'{byte:02x}' for byte in nonce)\n",
    "print(f\"Nonce: {hex_nonce}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# The keystream is a hexadecimal string.\n",
    "# It is a sequence of hexadecimal digits that represent the keystream generated by the ChaCha20 algorithm.\n",
    "# The keystream is used in the encryption process to combine with the plaintext to produce the ciphertext.\n",
    "# The keystream is generated based on the key and nonce, and it is the same length as the plaintext or ciphertext.\n",
    "\n",
    "# STM keystream\n",
    "keystream_str = \"73e96f51a6b7eeb730563e7db6f7ee22a95997abc498a52c141a1941769b3734805bcb9f529d93fcfbb46752889d4e560538c5e7d0a7cbce6e66da115323097b\"\n",
    "\n",
    "# XMEGA keystream\n",
    "# keystream_str = \"70b602649c3f6fc355e0cd92c77945e825eaf2e0c1bb90e9e09fa8635a786b62b897af7729b9c76894a9a864af4245e722963a355be562c80314b9a2562694b4\"\n",
    "\n",
    "# Step 1: Split the string into pairs of hexadecimal digits\n",
    "hex_pairs = [keystream_str[i:i+2] for i in range(0, len(keystream_str), 2)]\n",
    "\n",
    "# Step 2: Convert each pair into an integer\n",
    "byte_values = [int(hex_pair, 16) for hex_pair in hex_pairs]\n",
    "\n",
    "# Step 3: Create a NumPy array from these integers\n",
    "keystream = np.array(byte_values, dtype=np.uint8)\n",
    "\n",
    "hex_keystream = ''.join(f'{byte:02x}' for byte in keystream)\n",
    "print(f\"Keystream: {hex_keystream}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACES_RANDOM = None\n",
    "\n",
    "traces_list = []\n",
    "# Read the traces from the binary files in the specified folder.\n",
    "# The traces are stored in chunks, and each chunk is a binary file.\n",
    "# The chunk files are named \"traces_random.bin\" and are stored in folders named \"chunk_0\", \"chunk_1\", etc.\n",
    "for chunk_index in range(CHUNKS_CNT):\n",
    "    chunk_folder = os.path.join(FOLDER, f\"chunk_{chunk_index}\")\n",
    "    chunk_file = os.path.join(chunk_folder, \"traces_random.bin\")\n",
    "\n",
    "    if os.path.exists(chunk_file):\n",
    "        with open(chunk_file, 'rb') as file:\n",
    "            byte_array = file.read()\n",
    "\n",
    "        if chunk_index != CHUNKS_CNT-1:\n",
    "            chunk_traces = np.frombuffer(byte_array, dtype=np.uint16).reshape((CHUNK_SIZE, TRACE_LEN))\n",
    "        else:\n",
    "            chunk_traces = np.frombuffer(byte_array, dtype=np.uint16).reshape((LAST_CHUNK_SIZE, TRACE_LEN))\n",
    "\n",
    "        traces_list.append(chunk_traces)\n",
    "    else:\n",
    "        print(f\"Chunk file {chunk_file} does not exist.\")\n",
    "\n",
    "# Concatenate all chunks\n",
    "TRACES_RANDOM = np.vstack(traces_list)\n",
    "\n",
    "\n",
    "# Desired shape\n",
    "desired_shape = (TRACE_CNT, TRACE_LEN)\n",
    "\n",
    "# Check if the array has the desired shape\n",
    "if TRACES_RANDOM.shape != desired_shape:\n",
    "    # Trim the array to the desired shape\n",
    "    TRACES_RANDOM = TRACES_RANDOM[:desired_shape[0], :desired_shape[1]]\n",
    "    print(f\"Trimming TRACES_RANDOM to {TRACES_RANDOM.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pylab as plt\n",
    "plt.figure()\n",
    "plt.title(f'First trace from set using constant PT - CHACHA20')\n",
    "plt.plot(TRACES_RANDOM[0], 'g')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea93c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHACHA_KEY_LEN_BYTES = 64\n",
    "VALUES_IN_BYTE = 256 #0...255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6105bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamming weight table for 8-bit values\n",
    "# This table is used to calculate the Hamming weight of a byte value.\n",
    "hamming_weight = [\n",
    "   0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4, 1, 2, \n",
    "   2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5, 1, 2, 2, 3, 2, 3, 3, 4, \n",
    "   2, 3, 3, 4, 3, 4, 4, 5, 2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, \n",
    "   5, 6, 1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5, 2, 3, 3, 4, \n",
    "   3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6, 2, 3, 3, 4, 3, 4, 4, 5, 3, 4, \n",
    "   4, 5, 4, 5, 5, 6, 3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7, \n",
    "   1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5, 2, 3, 3, 4, 3, 4, \n",
    "   4, 5, 3, 4, 4, 5, 4, 5, 5, 6, 2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, \n",
    "   4, 5, 5, 6, 3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7, 2, 3, \n",
    "   3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6, 3, 4, 4, 5, 4, 5, 5, 6, \n",
    "   4, 5, 5, 6, 5, 6, 6, 7, 3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, \n",
    "   6, 7, 4, 5, 5, 6, 5, 6, 6, 7, 5, 6, 6, 7, 6, 7, 7, 8]\n",
    "\n",
    "def corr2_coeff(A, B):\n",
    "    \"\"\"\n",
    "    Calculate the correlation coefficient between two matrices A and B.\n",
    "    Each row of A and B is treated as a separate variable.\n",
    "    The function returns a matrix of correlation coefficients.\n",
    "    \"\"\"\n",
    "    # Rowwise mean of input arrays & subtract from input arrays themeselves\n",
    "    A_mA = A - A.mean(1)[:, None]\n",
    "    B_mB = B - B.mean(1)[:, None]\n",
    "\n",
    "    # Sum of squares across rows\n",
    "    ssA = (A_mA**2).sum(1)\n",
    "    ssB = (B_mB**2).sum(1)\n",
    "\n",
    "    # Finally get corr coeff\n",
    "    return np.dot(A_mA, B_mB.T) / np.sqrt(np.dot(ssA[:, None],ssB[None]))\n",
    "\n",
    "def check_obtained_key(correct_key, obtained_key_range):\n",
    "    \"\"\"\n",
    "    Check the obtained key against the keystream generated using the correct key and print the result.\n",
    "    The function compares each byte of the obtained key with the correct key and counts the number of correct bytes.\n",
    "    It also prints a summary of the comparison.\n",
    "    \"\"\"\n",
    "    correct_count = 0\n",
    "    comparison_result = []\n",
    "\n",
    "    for i in range(len(correct_key)):\n",
    "        if correct_key[i] == obtained_key_range[i]:\n",
    "            correct_count += 1\n",
    "            comparison_result.append('✔️')\n",
    "        else:\n",
    "            comparison_result.append('❌')\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"{correct_count} / {len(correct_key)} bytes correct:\")\n",
    "    print(' '.join(comparison_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_array_in_hex(array):\n",
    "    # Define a function to convert a single number to hexadecimal\n",
    "    def to_hex(x):\n",
    "        return hex(x)\n",
    "    \n",
    "    # Vectorize the to_hex function\n",
    "    vectorized_to_hex = np.vectorize(to_hex)\n",
    "    \n",
    "    # Apply the vectorized function to the array\n",
    "    hex_array = vectorized_to_hex(array)\n",
    "    \n",
    "    # Print the resulting array\n",
    "    print(hex_array)\n",
    "    \n",
    "def print_array_in_binary(array):\n",
    "    # Define a function to convert a single number to binary\n",
    "    def to_binary(x):\n",
    "        return bin(x)\n",
    "    \n",
    "    # Vectorize the to_binary function\n",
    "    vectorized_to_binary = np.vectorize(to_binary)\n",
    "    \n",
    "    # Apply the vectorized function to the array\n",
    "    binary_array = vectorized_to_binary(array)\n",
    "    \n",
    "    # Print the resulting array\n",
    "    print(binary_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59406b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlations_for_byte(byte_number):\n",
    "    \"\"\"\n",
    "    Calculate the correlation matrix for a specific byte of the ciphertext.\n",
    "    The function computes the Hamming weight for each possible value of the byte and calculates the correlation with the traces.\n",
    "    \"\"\"\n",
    "    global TRACE_CNT,VALUES_IN_BYTE, PLAINTEXTS, TRACES_RANDOM\n",
    "    L_v1_v2 = np.empty((TRACE_CNT,VALUES_IN_BYTE), dtype=np.uint16)\n",
    "    \n",
    "    for j in range(TRACE_CNT):\n",
    "        # i-th byte of CT matching the j-th trace\n",
    "        ct_byte = PLAINTEXTS[j][byte_number] \n",
    "        # XOR CT[j][i] with 0...255\n",
    "        v1_v2_line = np.array([ct_byte ^ key_val for key_val in range(VALUES_IN_BYTE)], dtype=np.uint16)\n",
    "      \n",
    "        L_v1_v2_line = np.array([hamming_weight[v1] for v1 in v1_v2_line], dtype=np.uint16)\n",
    "        L_v1_v2[j, :] = L_v1_v2_line\n",
    "\n",
    "    correlations = corr2_coeff(L_v1_v2.T, TRACES_RANDOM.T)\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5206165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STM32 - Trim TRACES_RANDOM to have only the first 23 traces\n",
    "TRACE_CNT = 23\n",
    "TRACES_RANDOM = TRACES_RANDOM[:TRACE_CNT, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e335a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XMEGA - Trim TRACES_RANDOM \n",
    "OFFSET = 0\n",
    "TRACE_CNT = 2650\n",
    "TRACES_RANDOM = TRACES_RANDOM[OFFSET:OFFSET+TRACE_CNT, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde69559",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = []\n",
    "for i in range(CHACHA_KEY_LEN_BYTES):\n",
    "    correlations.append(get_correlations_for_byte(i))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9133f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if correlations:\n",
    "    print(f\"Size of the first correlation matrix: {correlations[0].shape}\")\n",
    "    print(f\"Size of the first TRACES_RANDOM: {len(TRACES_RANDOM)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae0331",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORR_TRESHOLD = 0.5\n",
    "INDENTATION = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21c3056",
   "metadata": {},
   "source": [
    "## XMEGA CPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_CPA_in_range(list_of_correlations = [], start = 0, end = CHACHA_KEY_LEN_BYTES, graph = False):\n",
    "    \"\"\"\n",
    "    Perform Correlation Power Analysis (CPA) in a specified range of bytes.\n",
    "    The function calculates the correlation coefficients for each byte in the specified range and identifies the key byte with the highest correlation (min correlation in a row).\n",
    "    It also plots the correlation coefficients for visualization.\n",
    "\n",
    "    Parameters:\n",
    "    - list_of_correlations: List of correlation matrices for each byte.\n",
    "    - start: Starting index of the byte range to analyze.\n",
    "    - end: Ending index of the byte range to analyze.\n",
    "    - graph: Boolean flag to indicate whether to plot the correlation coefficients.\n",
    "\n",
    "    Returns:\n",
    "    - obtained_key_range: Array of obtained key bytes in the specified range.\n",
    "    \"\"\"\n",
    "\n",
    "    global REMOVED_CHUNK_CORR_TRESHOLD, REMOVED_CHUNK_SIZE\n",
    "\n",
    "    obtained_key_range = np.zeros(CHACHA_KEY_LEN_BYTES, dtype=np.ubyte)\n",
    "    bytes_with_max_sum_index = np.zeros(CHACHA_KEY_LEN_BYTES, dtype=np.ubyte)\n",
    "    for ANALYZED_BYTE in range(start, end):\n",
    "        correlations = []\n",
    "        if not list_of_correlations:\n",
    "#             print(\"The list of correlations is empty\")\n",
    "            correlations = get_correlations_for_byte(ANALYZED_BYTE)\n",
    "        else:\n",
    "#             print(\"The list of correlations is not empty\")\n",
    "            correlations = list_of_correlations[ANALYZED_BYTE].copy()  # Create a copy\n",
    "\n",
    "        start_col =0    \n",
    "        # Iterate through each row to find the first column from the right with abs(correlation) >= 0.5\n",
    "        col_index_max = -1\n",
    "        for row_index, row in enumerate(correlations):\n",
    "            for col_index in range(len(row) - 1, -1, -1):\n",
    "                if abs(row[col_index]) >= CORR_TRESHOLD and col_index_max < col_index:\n",
    "                    print (\"Col = \", col_index)\n",
    "                    col_index_max = col_index\n",
    "                    break  # Stop after finding the first column from the right\n",
    "                    \n",
    "        start_col = max(0, col_index_max - INDENTATION)\n",
    "        end_col = min(len(correlations[0]), col_index_max + INDENTATION)\n",
    "        \n",
    "        correlations = correlations[:, start_col:end_col]\n",
    "        corr_min = np.unravel_index(correlations.argmin(), correlations.shape)\n",
    "        obtained_key = corr_min[0]\n",
    "        print(f\"Obtained Expanded Key[{ANALYZED_BYTE}] = {hex(corr_min[0])} with min. correlation {correlations[corr_min[0]][corr_min[1]]} at position {corr_min[1]}\")\n",
    "        \n",
    "        if graph:\n",
    "            plt.figure(figsize=(7, 3))\n",
    "            for corr_i in range(VALUES_IN_BYTE):\n",
    "                if corr_i != keystream[0] and corr_i != corr_min[0]:\n",
    "                    plt.plot(list_of_correlations[ANALYZED_BYTE][corr_i], 'k')\n",
    "#             plt.plot(list_of_correlations[ANALYZED_BYTE][keystream[ANALYZED_BYTE]], 'g', alpha=0.6, label=\"Correct key\")\n",
    "            plt.plot(list_of_correlations[ANALYZED_BYTE][obtained_key], 'r', label=\"Correct key\")\n",
    "            plt.ylim(-1, 1)\n",
    "            # Highlight the lowest value in yellow\n",
    "            plt.scatter(corr_min[1]+ start_col, list_of_correlations[ANALYZED_BYTE][corr_min[0], corr_min[1] + start_col], color='yellow', zorder=5, label=f'The lowest value in a range ({start_col}, {end_col})')\n",
    "#             plt.axvline(x=start_col, color='green', linestyle='--')\n",
    "#             plt.axvline(x=end_col, color='green', linestyle='--')\n",
    "            plt.ylabel('Correlation')\n",
    "            plt.xlabel('Trace sample')\n",
    "#             plt.xlim(400, 600)  # Limit the x-axis range to 0-1000\n",
    "            plt.legend(loc='upper left')\n",
    "            plt.show()\n",
    "        \n",
    "        obtained_key_range[ANALYZED_BYTE] = obtained_key\n",
    "    return obtained_key_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b433b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "obtained_key_range = perform_CPA_in_range(correlations, 63, 64, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf2fdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obtained_key_range = perform_CPA_in_range(correlations, 0, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e59657",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_obtained_key(keystream, obtained_key_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51038e2",
   "metadata": {},
   "source": [
    "## STM CPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74eea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_CPA_in_range_STM(list_of_correlations = [], start = 0, end = CHACHA_KEY_LEN_BYTES, graph = False):\n",
    "    \"\"\"\n",
    "    Perform Correlation Power Analysis (CPA) in a specified range of bytes, modified for STM platform.\n",
    "    The function calculates the correlation coefficients for each byte in the specified range and identifies the key byte with the highest correlation (min correlation in a row).\n",
    "    It also plots the correlation coefficients for visualization.\n",
    "\n",
    "    Parameters:\n",
    "    - list_of_correlations: List of correlation matrices for each byte.\n",
    "    - start: Starting index of the byte range to analyze.\n",
    "    - end: Ending index of the byte range to analyze.\n",
    "    - graph: Boolean flag to indicate whether to plot the correlation coefficients.\n",
    "\n",
    "    Returns:\n",
    "    - obtained_key_range: Array of obtained key bytes in the specified range.\n",
    "    \"\"\"\n",
    "    global REMOVED_CHUNK_CORR_TRESHOLD, REMOVED_CHUNK_SIZE\n",
    "    obtained_key_range = np.zeros(CHACHA_KEY_LEN_BYTES, dtype=np.ubyte)\n",
    "    bytes_with_max_sum_index = np.zeros(CHACHA_KEY_LEN_BYTES, dtype=np.ubyte)\n",
    "    \n",
    "    min_guess_correct_cnt = 0\n",
    "    \n",
    "    for ANALYZED_BYTE in range(start, end):\n",
    "        correlations = []\n",
    "        if not list_of_correlations:\n",
    "            print(\"The list of correlations is empty\")\n",
    "            correlations = get_correlations_for_byte(ANALYZED_BYTE)\n",
    "        else:\n",
    "            print(\"The list of correlations is not empty\")\n",
    "            correlations = list_of_correlations[ANALYZED_BYTE].copy()  # Create a copy\n",
    "\n",
    "        corr_min = np.unravel_index(correlations.argmin(), correlations.shape)\n",
    "        obtained_key = corr_min[0]\n",
    "        print(f\"Obtained Expanded Key [{ANALYZED_BYTE}] = {hex(corr_min[0])} with min. correlation {correlations[corr_min[0]][corr_min[1]]} at position {corr_min[1]}\")\n",
    "  \n",
    "        start = max(0, corr_min[1] - 100)\n",
    "        end = min(len(correlations[0]), corr_min[1] + 100)\n",
    "        result = \"\"\n",
    "        \n",
    "        if keystream[ANALYZED_BYTE] == corr_min[0]:\n",
    "            min_guess_correct_cnt += 1\n",
    "#             print(f\"min_guess_correct_cnt - Key[{ANALYZED_BYTE}] = {hex(corr_min[0])} with min. correlation {correlations[corr_min[0]][corr_min[1]]} at position {corr_min[1]}\")\n",
    "\n",
    "        if keystream[ANALYZED_BYTE] == obtained_key:\n",
    "            result = \"=\"\n",
    "        else:\n",
    "            result = \"!\"\n",
    "            print(f\"Wrong Key[{ANALYZED_BYTE}]\")\n",
    "\n",
    "        if graph:\n",
    "            plt.figure(figsize=(7, 3))\n",
    "            for corr_i in range(VALUES_IN_BYTE):\n",
    "                if corr_i != keystream[0] and corr_i != corr_min[0]:\n",
    "                    plt.plot(correlations[corr_i], 'k')\n",
    "#             plt.plot(correlations[keystream[ANALYZED_BYTE]], 'g.', alpha=0.6, label=f'keystream[{ANALYZED_BYTE}] = {hex(keystream[ANALYZED_BYTE])}')\n",
    "            plt.plot(correlations[obtained_key], 'r')\n",
    "            plt.ylim(-1, 1)\n",
    "            # Highlight the lowest value in yellow\n",
    "            plt.scatter(corr_min[1], correlations[corr_min[0], corr_min[1]], color='yellow', zorder=5, label='Lowest value')\n",
    "\n",
    "            plt.ylabel('Correlation')\n",
    "            plt.xlabel('Trace sample')\n",
    "            plt.show()\n",
    "\n",
    "        obtained_key_range[ANALYZED_BYTE] = obtained_key\n",
    "    print (f\"min_guess_correct_cnt = {min_guess_correct_cnt}\")\n",
    "    return obtained_key_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636f629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obtained_key_range = perform_CPA_in_range_STM(correlations, 0, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f2a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_obtained_key(keystream, obtained_key_range)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "obtained_key_range = perform_CPA_in_range_STM(correlations, 0, 1, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
